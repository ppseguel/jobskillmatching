{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "industry_script.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ppseguel/jobskillmatching/blob/master/industry_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxsIaud5tFfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import dataset\n",
        "#follow this documentation, using Github, https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/ppseguel/jobskillmatching/master/marketingintern_industry.csv'\n",
        "job_data = pd.read_csv(url)\n",
        "#job_data = pd.read_csv(url, sep=',').values\n",
        "#job_data = pd.DataFrame(job_data)\n",
        "#job_data = job_data.values\n",
        "\n",
        "\n",
        "df = pd.DataFrame(job_data)\n",
        "df1 = df.fillna(0)\n",
        "\n",
        "df1.columns\n",
        "df1 = df1.rename(columns={\"Unnamed: 0\": \"id\", \"Linkedin/bloomberg\":\"LinkedInBloomerg\"})\n",
        "\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "\n",
        "#dataset = p.read_csv('dataset.csv', sep=',').values\n",
        "#dataset = p.DataFrame(dataset)\n",
        "#dataset = dataset.values\n",
        "\n",
        "\n",
        "#filling blank cells\n",
        "#from sklearn.preprocessing import Imputer\n",
        "#imputer = Imputer(missing_values='NaN', strategy='mean', axis = 0)\n",
        "#imputer = imputer.fit(job_data[:, 2:6])\n",
        "#job_data[:, 2:6] = imputer.transform(job_data[:, 2:6])\n",
        "#dataset = p.DataFrame(dataset)\n",
        "#dataset = dataset.values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGb1yO7kOfui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#turning textual data to numerical\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#labelencoder_0 = LabelEncoder() #independent variable encoder\n",
        "#job_data[:,0] = labelencoder_0.fit_transform(job_data[:,0])\n",
        "#labelencoder_1 = LabelEncoder() #independent variable encoder\n",
        "#dataset[:,1] = labelencoder_1.fit_transform(job_data[:,1])\n",
        "#labelencoder_6 = LabelEncoder() #dependent (target) variable encoder\n",
        "#job_data[:,6] = labelencoder_6.fit_transform(job_data[:,6])\n",
        "#dataset = p.DataFrame(dataset)\n",
        "#dataset = dataset.values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BTer7m1JbI0-",
        "colab": {}
      },
      "source": [
        "#Check the dataset\n",
        "#print(job_data)\n",
        "#print(df1)\n",
        "#df1.head()\n",
        "#job_data.head()\n",
        "\n",
        "#print(job_data.Groups, job_data.tableau)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zJTN3J0CVS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EXPERIMENT 1 (EDIT DATASET)\n",
        "\n",
        "# 1. Construct Datasets for Training and Evaluation\n",
        "#selecting y and x variables\n",
        "\n",
        "#splitting the dataset into the source variables (independant variables) and the target variable (dependant variable)\n",
        "#sourcevars = d[[\"agr\",\"art\"] #all columns except the last one\n",
        "#targetvar = df[1] #only the last column\n",
        "\n",
        "sourcevars = df1[df1.columns[-31:-1]] # Remember, Python is 0-offset! The \"3rd\" entry is at slot 2.           \n",
        "targetvar = df1[df1.columns[1:18]] # Remember, Python is 0-offset! The \"3rd\" entry is at slot 2.\n",
        "               \n",
        "X = sourcevars\n",
        "y = targetvar \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKpypf5CZUyP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2176
        },
        "outputId": "d1d7ab9b-c9d3-4fe4-9145-6f8dadc4534a"
      },
      "source": [
        "#targetvar.head()\n",
        "print(y)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     agr  art  cons  corp  edu  fin  good  gov  hlth  leg  man  med  org  rec  \\\n",
            "0    1.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "1    1.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "2    0.0  1.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  1.0  0.0  0.0   \n",
            "3    0.0  1.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  1.0  0.0  0.0   \n",
            "4    0.0  1.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  1.0  0.0  0.0   \n",
            "5    0.0  1.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  1.0  0.0  0.0   \n",
            "6    0.0  1.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  1.0  0.0  1.0   \n",
            "7    0.0  1.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  1.0  0.0  1.0   \n",
            "8    0.0  1.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  1.0  0.0  1.0   \n",
            "9    0.0  1.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  1.0  0.0  1.0   \n",
            "10   0.0  1.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  1.0  0.0  1.0   \n",
            "11   0.0  1.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  1.0  0.0  1.0   \n",
            "12   0.0  1.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  1.0  0.0  1.0   \n",
            "13   0.0  1.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  1.0   \n",
            "14   0.0  1.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  1.0   \n",
            "15   0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "16   0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "17   0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "18   0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "19   0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "20   0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "21   0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "22   0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "23   0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "24   0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "25   0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "26   0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "27   0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "28   0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "29   0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "..   ...  ...   ...   ...  ...  ...   ...  ...   ...  ...  ...  ...  ...  ...   \n",
            "730  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "731  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "732  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "733  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "734  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "735  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "736  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "737  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "738  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "739  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "740  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "741  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "742  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "743  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "744  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "745  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "746  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "747  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "748  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "749  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "750  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "751  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "752  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "753  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "754  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "755  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "756  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "757  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "758  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "759  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "\n",
            "     serv  tech  tran  \n",
            "0     0.0   0.0   0.0  \n",
            "1     0.0   0.0   0.0  \n",
            "2     0.0   0.0   0.0  \n",
            "3     0.0   0.0   0.0  \n",
            "4     0.0   0.0   0.0  \n",
            "5     0.0   0.0   0.0  \n",
            "6     0.0   0.0   0.0  \n",
            "7     0.0   0.0   0.0  \n",
            "8     0.0   0.0   0.0  \n",
            "9     0.0   0.0   0.0  \n",
            "10    0.0   0.0   0.0  \n",
            "11    0.0   0.0   0.0  \n",
            "12    0.0   0.0   0.0  \n",
            "13    0.0   0.0   0.0  \n",
            "14    0.0   0.0   0.0  \n",
            "15    0.0   0.0   0.0  \n",
            "16    0.0   0.0   0.0  \n",
            "17    0.0   0.0   0.0  \n",
            "18    0.0   0.0   0.0  \n",
            "19    0.0   0.0   0.0  \n",
            "20    0.0   0.0   0.0  \n",
            "21    0.0   0.0   0.0  \n",
            "22    0.0   0.0   0.0  \n",
            "23    0.0   0.0   0.0  \n",
            "24    0.0   0.0   0.0  \n",
            "25    0.0   0.0   0.0  \n",
            "26    0.0   0.0   0.0  \n",
            "27    0.0   0.0   0.0  \n",
            "28    0.0   0.0   0.0  \n",
            "29    0.0   0.0   0.0  \n",
            "..    ...   ...   ...  \n",
            "730   0.0   0.0   0.0  \n",
            "731   0.0   0.0   0.0  \n",
            "732   0.0   0.0   0.0  \n",
            "733   0.0   0.0   0.0  \n",
            "734   0.0   0.0   0.0  \n",
            "735   0.0   0.0   0.0  \n",
            "736   0.0   0.0   0.0  \n",
            "737   0.0   0.0   0.0  \n",
            "738   0.0   0.0   0.0  \n",
            "739   0.0   0.0   0.0  \n",
            "740   0.0   0.0   0.0  \n",
            "741   0.0   0.0   0.0  \n",
            "742   0.0   0.0   0.0  \n",
            "743   0.0   0.0   0.0  \n",
            "744   0.0   0.0   0.0  \n",
            "745   0.0   0.0   0.0  \n",
            "746   0.0   0.0   0.0  \n",
            "747   0.0   0.0   0.0  \n",
            "748   0.0   0.0   0.0  \n",
            "749   0.0   0.0   0.0  \n",
            "750   0.0   0.0   0.0  \n",
            "751   0.0   0.0   0.0  \n",
            "752   0.0   0.0   0.0  \n",
            "753   0.0   0.0   0.0  \n",
            "754   0.0   0.0   0.0  \n",
            "755   0.0   0.0   0.0  \n",
            "756   0.0   0.0   0.0  \n",
            "757   0.0   0.0   0.0  \n",
            "758   0.0   0.0   0.0  \n",
            "759   0.0   0.0   0.0  \n",
            "\n",
            "[760 rows x 17 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iog_PexN5JK",
        "colab_type": "code",
        "outputId": "8cae34bd-4dea-47f5-9381-17148b7a1461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# b) Construct Datasets for Training and Evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.25, random_state=42)\n",
        "print(\"Number samples in training: \", len(X_train))\n",
        "print(\"Number samples in testing: \", len(X_test))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number samples in training:  570\n",
            "Number samples in testing:  190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtX_Do-WYTSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1d57f892-7f2e-4254-d130-1285bd1ab182"
      },
      "source": [
        "#!pip install -q skmultilearn.adapt\n",
        "!pip install scikit-multilearn\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-multilearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 5.7MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzJbj6BTYa-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99cc2602-53ae-40e2-a6d4-093a10bde329"
      },
      "source": [
        "# using classifier chains\n",
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# initialize classifier chains multi-label classifier\n",
        "# with a gaussian naive bayes base classifier\n",
        "classifier = ClassifierChain(DecisionTreeClassifier())\n",
        "\n",
        "# train\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "predictions = classifier.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test,predictions)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18421052631578946"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9mr_U6_ZXc4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64c10058-1a36-41bb-94c8-34df07106f31"
      },
      "source": [
        "# using classifier chains\n",
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# initialize classifier chains multi-label classifier\n",
        "# with a gaussian naive bayes base classifier\n",
        "Knclassifier = ClassifierChain(KNeighborsClassifier())\n",
        "\n",
        "# train\n",
        "Knclassifier.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "predictions = Knclassifier.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test,predictions)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12631578947368421"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmVwNSJlRATJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree_giniIndex = DecisionTreeClassifier(criterion='entropy', max_depth=6, class_weight=\"balanced\")\n",
        "tree_giniIndex.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O52qMgUNEFmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EXPERIMENT 1 (EDIT DATASET AND TO MULTILABEL)\n",
        "\n",
        "# a) Train and evaluate a decision treel model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree_giniIndex = DecisionTreeClassifier(criterion='entropy', max_depth=6)\n",
        "tree_giniIndex.fit(X_train, y_train)\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=2)\n",
        "tree_scores = cross_val_score(tree_giniIndex, X, y, cv=kfold, scoring=\"accuracy\")\n",
        "print(\"Cross-validation score:\\n{}\".format(tree_scores))\n",
        "print(\"Average cross-validation score: {:.2f}\".format(tree_scores.mean()))\n",
        "print(\"Standard deviation: {:.2f}\".format(tree_scores.std()))\n",
        "\n",
        "# Tune Decision Tree hyperparameter using cross-validation\n",
        "best_score = 0\n",
        "for max_d in [1,3,5,7,9,11,13,15,17]:\n",
        "    \n",
        "    tree_giniIndex = DecisionTreeClassifier(max_depth=max_d).fit(X_train, y_train)\n",
        "    fold_accuracies = cross_val_score(tree_giniIndex, X_train, y_train, cv=kfold, scoring=\"accuracy\") \n",
        "    score = fold_accuracies.mean()\n",
        "    \n",
        "    print(\"Score for depth of \" + str(max_d) + \"on validation set is {:0.2f}\".format(score))\n",
        "    \n",
        "    #Best score for best optimal model\n",
        "    \n",
        "    if score > best_score:\n",
        "        best_param = {'max_depth': max_d}\n",
        "        best_score = score\n",
        "        \n",
        "#Part of the answer of question 3        \n",
        "tree_giniIndex = DecisionTreeClassifier(**best_param)\n",
        "tree_giniIndex.fit(X_train, y_train)\n",
        "test_score = tree_giniIndex.score(X_test, y_test)\n",
        "print(\"Best score on cross-validation: {:0.2f}\".format(best_score))\n",
        "print(\"Best parameters: {}\".format(best_param))\n",
        "print(\"Test set score: {:.2f}\".format(test_score))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMXdhZlXEQXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EXPERIMENT 1 (EDIT DATASET AND TO MULTILABEL)\n",
        "\n",
        "\n",
        "# b) Nearest Neighbors (K-NN)\n",
        "# Normalize data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "mms = MinMaxScaler()\n",
        "X_train_norm = mms.fit_transform(X_train)\n",
        "X_test_norm = mms.transform(X_test)\n",
        "\n",
        "# Tune hyperparameters using cross-validation for K-NN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=2)\n",
        "\n",
        "best_score = 0\n",
        "\n",
        "for p in [1, 2, 3, 4, 5]:\n",
        "    for n in [1, 2, 3, 4, 5, 6]:   \n",
        "        clf = KNeighborsClassifier(n_neighbors=n, p=p, metric='minkowski')\n",
        "        clf.fit(X_train_norm, y_train)\n",
        "            \n",
        "        fold_accuracies = cross_val_score(clf, X_train, y_train, cv=kfold, scoring=\"accuracy\")  \n",
        "        score = fold_accuracies.mean()\n",
        "        print(\"Score for p \" + str(p) + \", score of neighbors \" + str(n) + \" on validation set is {:0.2f}\".format(score))\n",
        "    \n",
        "        if score > best_score:\n",
        "            best_param = {\"p\": p, \"neighbors\": n}\n",
        "            best_score = score\n",
        "\n",
        "#rebuild the model and evaluate the test score                \n",
        "clf = KNeighborsClassifier(**best_param)\n",
        "clf.fit(X_train_norm, y_train)\n",
        "test_score = clf.score(X_test_norm, y_test)\n",
        "print(\"Best score on cross-validation: {:0.2f}\".format(best_score))\n",
        "print(\"Best parameters: {}\".format(best_param))\n",
        "print(\"Test set score: {:.2f}\".format(test_score))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSMVkt0lEqZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3 Optimal Decision Tree model predictive performance\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree_giniIndex = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
        "tree_giniIndex.fit(X_train, y_train)\n",
        "\n",
        "y_predictedDT = tree_giniIndex.predict(X_test_scaled)\n",
        "print(metrics.classification_report(y_predictedDT, y_test))\n",
        "print(metrics.accuracy_score(y_predictedDT, y_test))\n",
        "\n",
        "#3 Optimal SVM model predictive performance\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "poly_kernel_svm_clf = SVC(kernel=\"poly\", C = 1, degree=0, gamma=0.1)\n",
        "poly_kernel_svm_clf.fit(X_train_scaled, y_train)\n",
        "y_predictedSVM = poly_kernel_svm_clf.predict(X_test_scaled)\n",
        "print(metrics.classification_report(y_predictedSVM, y_test))\n",
        "print(metrics.accuracy_score(y_predictedSVM, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS5QS28NEr9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize confusion matrix for the Naive Bayes\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "mat = confusion_matrix(y_predictedNB, y_test)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label')\n",
        "\n",
        "# Visualize confusion matrix for Decision Tree\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "mat = confusion_matrix(y_predictedDT, y_test)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label')\n",
        "\n",
        "# Visualize confusion matrix for the SVM\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "mat = confusion_matrix(y_predictedSVM, y_test)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi0A_RdeFpzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MULTILABEL CONFUSION MATRIX\n",
        "import numpy as np\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "multilabel_confusion_matrix(y_true, y_pred, sample_weight=None, labels=None, samplewise=False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAZleTMVCbvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EXPERIMENT 2\n",
        "# Plot learning curves\n",
        "def plot_learning_curves(model, x, y):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
        "    train_errors, test_errors = [], []\n",
        "   # change de len for m in range(1, len(x_train)):\n",
        "    for m in range(1, 5):\n",
        "        model.fit(x_train[:m], y_train[:m])\n",
        "        y_train_predict = model.predict(x_train[:m])\n",
        "        y_test_predict = model.predict(x_test)\n",
        "        train_errors.append(mean_squared_error(y_train_predict, y_train[:m]))\n",
        "        test_errors.append(mean_squared_error(y_test_predict, y_test))\n",
        "        plt.plot(train_errors, \"r-+\", linewidth = 2, label = \"Training Data\")\n",
        "        plt.plot(test_errors, \"b-+\", linewidth = 3, label = \"Test Data\")\n",
        "        plt.ylabel(\"Mean squared error\")\n",
        "        plt.title(\"Learning Curves\")\n",
        "        plt.legend()\n",
        "        \n",
        "linear_reg_model = linear_model.LinearRegression()\n",
        "plot_learning_curves(linear_reg_model, x_real, y_real)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "426hEGx5bhpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using skmultilearn\n",
        "\n",
        "from skmultilearn.adapt import MLkNN\n",
        "\n",
        "classifier = MLkNN(k=20)\n",
        "\n",
        "# train\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "predictions = classifier.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test,predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}