{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "industry_script.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ppseguel/jobskillmatching/blob/master/industry_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vxsIaud5tFfD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import dataset\n",
        "#follow this documentation, using Github, https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/ppseguel/jobskillmatching/master/marketingintern_industry.csv'\n",
        "job_data = pd.read_csv(url)\n",
        "#job_data = pd.read_csv(url, sep=',').values\n",
        "#job_data = pd.DataFrame(job_data)\n",
        "#job_data = job_data.values\n",
        "\n",
        "\n",
        "df = pd.DataFrame(job_data)\n",
        "\n",
        "\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "\n",
        "#dataset = p.read_csv('dataset.csv', sep=',').values\n",
        "#dataset = p.DataFrame(dataset)\n",
        "#dataset = dataset.values\n",
        "\n",
        "\n",
        "#filling blank cells\n",
        "#from sklearn.preprocessing import Imputer\n",
        "#imputer = Imputer(missing_values='NaN', strategy='mean', axis = 0)\n",
        "#imputer = imputer.fit(job_data[:, 2:6])\n",
        "#job_data[:, 2:6] = imputer.transform(job_data[:, 2:6])\n",
        "#dataset = p.DataFrame(dataset)\n",
        "#dataset = dataset.values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oGb1yO7kOfui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d98a8904-61d0-4682-accc-84398e5f08d7"
      },
      "cell_type": "code",
      "source": [
        "#turning textual data to numerical\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#labelencoder_0 = LabelEncoder() #independent variable encoder\n",
        "#job_data[:,0] = labelencoder_0.fit_transform(job_data[:,0])\n",
        "#labelencoder_1 = LabelEncoder() #independent variable encoder\n",
        "#dataset[:,1] = labelencoder_1.fit_transform(job_data[:,1])\n",
        "#labelencoder_6 = LabelEncoder() #dependent (target) variable encoder\n",
        "#job_data[:,6] = labelencoder_6.fit_transform(job_data[:,6])\n",
        "#dataset = p.DataFrame(dataset)\n",
        "#dataset = dataset.values\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[H\u001b[2J"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OQ5AKKoEEdS0",
        "colab_type": "code",
        "outputId": "abdaaf91-4e58-4e39-8562-8787b77f72fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "cell_type": "code",
      "source": [
        "#Check the dataset\n",
        "#print(job_data)\n",
        "#print(df)\n",
        "df.head()\n",
        "#job_data.head()\n",
        "\n",
        "#print(job_data.Groups, job_data.tableau)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>agr</th>\n",
              "      <th>art</th>\n",
              "      <th>cons</th>\n",
              "      <th>corp</th>\n",
              "      <th>edu</th>\n",
              "      <th>fin</th>\n",
              "      <th>good</th>\n",
              "      <th>gov</th>\n",
              "      <th>hlth</th>\n",
              "      <th>...</th>\n",
              "      <th>presentation</th>\n",
              "      <th>detail</th>\n",
              "      <th>creative</th>\n",
              "      <th>pr</th>\n",
              "      <th>sales</th>\n",
              "      <th>content</th>\n",
              "      <th>analytics</th>\n",
              "      <th>social_media</th>\n",
              "      <th>digital</th>\n",
              "      <th>paid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>191</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>249</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>90</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 58 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  agr  art  cons  corp  edu  fin  good  gov  hlth  ...  \\\n",
              "0          42  0.0  0.0   0.0   0.0  0.0  0.0   1.0  0.0   0.0  ...   \n",
              "1         191  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  ...   \n",
              "2         249  0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0   0.0  ...   \n",
              "3          90  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  ...   \n",
              "4         149  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0   0.0  ...   \n",
              "\n",
              "   presentation  detail  creative  pr  sales  content  analytics  \\\n",
              "0             0       0         1   0      0        0          0   \n",
              "1             0       1         1   0      0        1          1   \n",
              "2             0       1         0   0      0        0          1   \n",
              "3             1       1         0   0      1        0          1   \n",
              "4             1       1         0   0      1        0          1   \n",
              "\n",
              "   social_media digital paid  \n",
              "0             1       0    1  \n",
              "1             1       1    1  \n",
              "2             0       0    0  \n",
              "3             0       0    0  \n",
              "4             0       1    1  \n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "6zJTN3J0CVS_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#EXPERIMENT 1 (EDIT DATASET)\n",
        "\n",
        "# 1. Construct Datasets for Training and Evaluation\n",
        "#selecting y and x variables\n",
        "\n",
        "#splitting the dataset into the source variables (independant variables) and the target variable (dependant variable)\n",
        "#sourcevars = job_data[:,:-1] #all columns except the last one\n",
        "#targetvar = job_data[1] #only the last column\n",
        "\n",
        "\n",
        "\n",
        "X = job_data.tableau\n",
        "y = job_data.Groups\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N4OMSTEzOeHI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9iog_PexN5JK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "862f54f1-365f-4174-8c90-97a85c67c714"
      },
      "cell_type": "code",
      "source": [
        "# b) Construct Datasets for Training and Evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "print(\"Number samples in training: \", len(X_train))\n",
        "print(\"Number samples in testing: \", len(X_test))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number samples in training:  570\n",
            "Number samples in testing:  190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nmVwNSJlRATJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "outputId": "b4cf0afc-e1c9-43fa-f256-d5cf069109de"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree_giniIndex = DecisionTreeClassifier(criterion='entropy', max_depth=6, class_weight=\"balanced\")\n",
        "tree_giniIndex.fit(X_train, y_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e32d1c16dcd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtree_giniIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtree_giniIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    550\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "O52qMgUNEFmT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#EXPERIMENT 1 (EDIT DATASET AND TO MULTILABEL)\n",
        "\n",
        "# a) Train and evaluate a decision treel model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree_giniIndex = DecisionTreeClassifier(criterion='entropy', max_depth=6)\n",
        "tree_giniIndex.fit(X_train, y_train)\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=2)\n",
        "tree_scores = cross_val_score(tree_giniIndex, X, y, cv=kfold, scoring=\"accuracy\")\n",
        "print(\"Cross-validation score:\\n{}\".format(tree_scores))\n",
        "print(\"Average cross-validation score: {:.2f}\".format(tree_scores.mean()))\n",
        "print(\"Standard deviation: {:.2f}\".format(tree_scores.std()))\n",
        "\n",
        "# Tune Decision Tree hyperparameter using cross-validation\n",
        "best_score = 0\n",
        "for max_d in [1,3,5,7,9,11,13,15,17]:\n",
        "    \n",
        "    tree_giniIndex = DecisionTreeClassifier(max_depth=max_d).fit(X_train, y_train)\n",
        "    fold_accuracies = cross_val_score(tree_giniIndex, X_train, y_train, cv=kfold, scoring=\"accuracy\") \n",
        "    score = fold_accuracies.mean()\n",
        "    \n",
        "    print(\"Score for depth of \" + str(max_d) + \"on validation set is {:0.2f}\".format(score))\n",
        "    \n",
        "    #Best score for best optimal model\n",
        "    \n",
        "    if score > best_score:\n",
        "        best_param = {'max_depth': max_d}\n",
        "        best_score = score\n",
        "        \n",
        "#Part of the answer of question 3        \n",
        "tree_giniIndex = DecisionTreeClassifier(**best_param)\n",
        "tree_giniIndex.fit(X_train, y_train)\n",
        "test_score = tree_giniIndex.score(X_test, y_test)\n",
        "print(\"Best score on cross-validation: {:0.2f}\".format(best_score))\n",
        "print(\"Best parameters: {}\".format(best_param))\n",
        "print(\"Test set score: {:.2f}\".format(test_score))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SMXdhZlXEQXt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#EXPERIMENT 1 (EDIT DATASET AND TO MULTILABEL)\n",
        "\n",
        "\n",
        "# b) Nearest Neighbors (K-NN)\n",
        "# Normalize data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "mms = MinMaxScaler()\n",
        "X_train_norm = mms.fit_transform(X_train)\n",
        "X_test_norm = mms.transform(X_test)\n",
        "\n",
        "# Tune hyperparameters using cross-validation for K-NN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=2)\n",
        "\n",
        "best_score = 0\n",
        "\n",
        "for p in [1, 2, 3, 4, 5]:\n",
        "    for n in [1, 2, 3, 4, 5, 6]:   \n",
        "        clf = KNeighborsClassifier(n_neighbors=n, p=p, metric='minkowski')\n",
        "        clf.fit(X_train_norm, y_train)\n",
        "            \n",
        "        fold_accuracies = cross_val_score(clf, X_train, y_train, cv=kfold, scoring=\"accuracy\")  \n",
        "        score = fold_accuracies.mean()\n",
        "        print(\"Score for p \" + str(p) + \", score of neighbors \" + str(n) + \" on validation set is {:0.2f}\".format(score))\n",
        "    \n",
        "        if score > best_score:\n",
        "            best_param = {\"p\": p, \"neighbors\": n}\n",
        "            best_score = score\n",
        "\n",
        "#rebuild the model and evaluate the test score                \n",
        "clf = KNeighborsClassifier(**best_param)\n",
        "clf.fit(X_train_norm, y_train)\n",
        "test_score = clf.score(X_test_norm, y_test)\n",
        "print(\"Best score on cross-validation: {:0.2f}\".format(best_score))\n",
        "print(\"Best parameters: {}\".format(best_param))\n",
        "print(\"Test set score: {:.2f}\".format(test_score))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kSMVkt0lEqZn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#3 Optimal Decision Tree model predictive performance\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree_giniIndex = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
        "tree_giniIndex.fit(X_train, y_train)\n",
        "\n",
        "y_predictedDT = tree_giniIndex.predict(X_test_scaled)\n",
        "print(metrics.classification_report(y_predictedDT, y_test))\n",
        "print(metrics.accuracy_score(y_predictedDT, y_test))\n",
        "\n",
        "#3 Optimal SVM model predictive performance\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "poly_kernel_svm_clf = SVC(kernel=\"poly\", C = 1, degree=0, gamma=0.1)\n",
        "poly_kernel_svm_clf.fit(X_train_scaled, y_train)\n",
        "y_predictedSVM = poly_kernel_svm_clf.predict(X_test_scaled)\n",
        "print(metrics.classification_report(y_predictedSVM, y_test))\n",
        "print(metrics.accuracy_score(y_predictedSVM, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vS5QS28NEr9-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualize confusion matrix for the Naive Bayes\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "mat = confusion_matrix(y_predictedNB, y_test)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label')\n",
        "\n",
        "# Visualize confusion matrix for Decision Tree\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "mat = confusion_matrix(y_predictedDT, y_test)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label')\n",
        "\n",
        "# Visualize confusion matrix for the SVM\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "mat = confusion_matrix(y_predictedSVM, y_test)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zi0A_RdeFpzO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#MULTILABEL CONFUSION MATRIX\n",
        "import numpy as np\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "multilabel_confusion_matrix(y_true, y_pred, sample_weight=None, labels=None, samplewise=False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FAZleTMVCbvw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#EXPERIMENT 2\n",
        "# Plot learning curves\n",
        "def plot_learning_curves(model, x, y):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
        "    train_errors, test_errors = [], []\n",
        "   # change de len for m in range(1, len(x_train)):\n",
        "    for m in range(1, 5):\n",
        "        model.fit(x_train[:m], y_train[:m])\n",
        "        y_train_predict = model.predict(x_train[:m])\n",
        "        y_test_predict = model.predict(x_test)\n",
        "        train_errors.append(mean_squared_error(y_train_predict, y_train[:m]))\n",
        "        test_errors.append(mean_squared_error(y_test_predict, y_test))\n",
        "        plt.plot(train_errors, \"r-+\", linewidth = 2, label = \"Training Data\")\n",
        "        plt.plot(test_errors, \"b-+\", linewidth = 3, label = \"Test Data\")\n",
        "        plt.ylabel(\"Mean squared error\")\n",
        "        plt.title(\"Learning Curves\")\n",
        "        plt.legend()\n",
        "        \n",
        "linear_reg_model = linear_model.LinearRegression()\n",
        "plot_learning_curves(linear_reg_model, x_real, y_real)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}